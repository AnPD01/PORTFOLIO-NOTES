import streamlit as st
import google.generativeai as genai

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë‚˜ë§Œì˜ AI ì±—ë´‡", page_icon="ğŸ¤–")

# ì œëª©
st.title("ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”")

# 1. API í‚¤ ì„¤ì • (ë¹„ë°€ë²ˆí˜¸ì²˜ëŸ¼ ìˆ¨ê²¨ì§„ í‚¤ë¥¼ ê°€ì ¸ì˜´)
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit ë°°í¬ ì„¤ì •ì—ì„œ Secretsë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# 2. ëª¨ë¸ ì„¤ì • (Gemini Pro)
model = genai.GenerativeModel('gemini-1.5-flash')

# 3. ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘)
if "messages" not in st.session_state:
    st.session_state.messages = []

# 4. ì´ì „ ëŒ€í™” ë‚´ìš© í™”ë©´ì— ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ
    with st.chat_message("user"):
        st.markdown(prompt)
    # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 6. AI ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # AIì—ê²Œ ì§ˆë¬¸ ì „ë‹¬ (ê³¼ê±° ëŒ€í™” ë§¥ë½ í¬í•¨í•˜ê³  ì‹¶ìœ¼ë©´ history ê´€ë¦¬ í•„ìš”)
            chat = model.start_chat(history=[]) 
            response = chat.send_message(prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)
            
            # AI ì‘ë‹µ ê¸°ë¡ì— ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
